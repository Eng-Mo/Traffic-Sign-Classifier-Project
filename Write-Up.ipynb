{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Traffic Sign Recognition-Project2-Report** \n",
    "\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[iSoft1]: ./SoftPredict0.png \"ImgSoft0\"\n",
    "[iSoft2]: ./SoftPredict1.png \"ImgSoft1\"\n",
    "[iSoft3]: ./SoftPredict2.png \"ImgSoft2\"\n",
    "[iSoft4]: ./SoftPredict3.png \"ImgSoft3\"\n",
    "[iSoft5]: ./SoftPredict4.png \"ImgSoft4\"\n",
    "[iSoft6]: ./SoftPredict5.png \"ImgSoft5\"\n",
    "[iSoft7]: ./SoftPredict6.png \"ImgSoft6\"\n",
    "[iSoft8]: ./SoftPredict0.png \"ImgSoft7\"\n",
    "\n",
    "\n",
    "**Data Set Summary & Exploration**\n",
    "\n",
    "The follwoing are the data exploration from test.p,train.p data and the number of unique classes were explored from signnames.csv.\n",
    "\n",
    "* The size of training set is 31367\n",
    "* The size of the validation set is 7842\n",
    "* The size of test set is 12630\n",
    "* The shape of a traffic sign image is (32, 32, 3)\n",
    "* The number of unique classes/labels in the data set is 43\n",
    "\n",
    "The images (train,validation,test) samples are presented below and the following chart shows the histogram of each class ID:\n",
    "\n",
    "\n",
    "![train sample][itrain]\n",
    "\n",
    "![alt text][ivalidation]\n",
    "\n",
    "![alt text][itest]\n",
    "\n",
    "![alt text][iHist] \n",
    "[itrain]: ./train.png \n",
    "[ivalidation]: ./validation.png \n",
    "[itest]: ./test.png \n",
    "[iHist]: ./class_histogram_plot.png \n",
    "\n",
    "**Design and Test a Model Architecture**\n",
    "\n",
    "Not many presprocerssing technioque was used as the only prerossessing was normalisation the test, train, valoidation set to reduce computation and big error when adding and multiplying the weights by using the follwing equation (X/122.5)-1 and the result as following:\n",
    "\n",
    "![alt text][iNorm] \n",
    "[iNorm]: ./normtest.png\n",
    "\n",
    "Note: converting to gary scale was attemted but not test as arised error says cann't feed dict with shape (64,32,32) with tensor (?,32,32,1) even after adding channel cololumnd to the data test. \n",
    "\n",
    "**Model Architecture**\n",
    "\n",
    "the Lenet model was chosen to start the experments. this work is adopted code of LeNet Lab That we studied in the class. the model is the same exept the batch size changed to 64 for better accuracy after trying 128,256. Basically I didnt went so deep to understand the architecture performance.\n",
    "\n",
    "My final model contaion the following layers:\n",
    "\n",
    "| Layer         \t\t|     Description\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "|Input         \t\t    | 32x32x3 RGB image   \t\t\t\t\t\t\t| \n",
    "|Convolution 5x5x6    \t| 1x1 stride, valid padding, outputs 28x28x6 \t|\n",
    "|RELU\t\t\t\t\t| outputs 28x28x6 \t\t\t\t\t\t\t\t|\n",
    "|Max pooling 28x25x6 \t| 2x2 stride,valid padding,output 14x14x6 \t\t|\n",
    "|Convolution 14x14x16   | 2x2 stride,valid padding,output 10x10x16      |\n",
    "|RELU                   |                          output 14x14x16      |\n",
    "|Max pooling 10x10x16   |                          Output = 5x5x16      |\n",
    "|flatten 5x5x16         |                          Output = 400         |\n",
    "|Fully connected 400\t|                          output =120    \t\t|\n",
    "|Fully connnected  120  |                          output =84           |\n",
    "|Fully connnected  84   |                          output =43           |\n",
    "|Softmax\t\t\t\t|                                  43           |\n",
    "\n",
    "\n",
    "The LeNet model was chosen and the hyperparameters were tuned try and error. the best result calculated using the following parameter values:\n",
    "\n",
    "* Epoch:10\n",
    "* Batch_Size=64\n",
    "* Sigma=.1\n",
    "* Learning rate= .003\n",
    "\n",
    "The mjor challenge was the not steady increasing in accuracy as it some point of Epochs can be decreased and the proposed tuning increase regulary except one epoch.Alos by increasing the learning rate to .003 it helped to keep the number of epochs to 10 to not increasse the computations. \n",
    "* validation set accuracy of %97\n",
    "* test set accuracy of %90\n",
    "\n",
    "\n",
    "\n",
    "**Test a Model on New Images**\n",
    "\n",
    "Here are five German traffic signs that I found on the web. The following images are the images before and after preprocessing.\n",
    "![alt text][image1]\n",
    "![alt text][image2]\n",
    "\n",
    "No Park sign was tested but excluded  as they are not listed in signname.csv and hence the prediction is totally wrong. Also, the images are collected from web and almost in good condition for predection.\n",
    "\n",
    "\n",
    "Here are the results of the prediction:\n",
    "\n",
    "| Image\t\t\t        |     Prediction\t        \t\t\t\t\t     | \n",
    "|:---------------------:|:---------------------------------------------:     | \n",
    "|Speed limit (30km/h)\t               |Speed limit (30km/h)\t\t         | \n",
    "|Right-of-way at the next intersection |Right-of-way at the next intersection|\n",
    "|Stop\t\t\t\t                   | No vehicles\t\t\t\t\t\t |\n",
    "|Keep right\t      \t                   | Keep right\t     \t\t\t\t     |\n",
    "|Speed limit (20km/h)\t\t           | Speed limit (20km/h) \t\t\t     |\n",
    "|Ahead only                            |Ahead only                           |\n",
    "|Speed limit (80km/h)                  |Speed limit (80km/h)                 |\n",
    "\n",
    "The model was able to correctly guess 4 of the 5 traffic signs with accuracy %85.7 and sometimes can achieve %100 \n",
    "\n",
    "The Following are the softmax propabilities for each new Images. The vaules shows high accuracy due to the clearness of the new test images as this project didn't considered new images with noise or in bad lighting conditions. \n",
    "\n",
    "Here are the results of the prediction:\n",
    "\n",
    "| Class ID \t\t\t                   |  Soft probability| \n",
    "|:------------------------------------:|:-----------------| \n",
    "|Speed limit (30km/h)\t               |%100\t\t      | \n",
    "|Right-of-way at the next intersection |%100              |\n",
    "|Speed limit (20km/h)                  | %81\t\t\t  |\n",
    "|Keep right\t      \t                   |%100     \t\t  |\n",
    "|Speed limit (20km/h)\t\t           | %100 \t\t\t  |\n",
    "|Ahead only                            |%100              |\n",
    "|Speed limit (80km/h)                  | %99.8            |\n",
    "\n",
    "![alt text][iSoft1]\n",
    "![alt text][iSoft2]\n",
    "![alt text][iSoft3]\n",
    "![alt text][iSoft4]\n",
    "![alt text][iSoft5]\n",
    "![alt text][iSoft6]\n",
    "![alt text][iSoft7]\n",
    "![alt text][iSoft8]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
